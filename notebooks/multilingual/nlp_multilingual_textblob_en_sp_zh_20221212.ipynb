{"cells":[{"cell_type":"markdown","source":["# NLP of Multilingual Texts using TextBlob (English, Spanish and Chinese)\n","\n","https://github.com/vitojph/kschool-nlp-18/blob/master/notebooks/textblob.ipynb\n","\n","Debugged/Extended by:\n","* Jon Chun\n","* 20221212"],"metadata":{"id":"x-kdxw6ExXEm"}},{"cell_type":"code","source":["!pip list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLAbVQUorDw6","executionInfo":{"status":"ok","timestamp":1670854236467,"user_tz":300,"elapsed":1531,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"6cc296d3-ea77-4f89-9c84-b6d22665a897"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Package                       Version\n","----------------------------- ----------------------\n","absl-py                       1.3.0\n","aeppl                         0.0.33\n","aesara                        2.7.9\n","aiohttp                       3.8.3\n","aiosignal                     1.3.1\n","alabaster                     0.7.12\n","albumentations                1.2.1\n","altair                        4.2.0\n","appdirs                       1.4.4\n","arviz                         0.12.1\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","async-timeout                 4.0.2\n","atari-py                      0.2.9\n","atomicwrites                  1.4.1\n","attrs                         22.1.0\n","audioread                     3.0.0\n","autograd                      1.5\n","Babel                         2.11.0\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        5.0.1\n","blis                          0.7.9\n","bokeh                         2.3.3\n","branca                        0.6.0\n","bs4                           0.0.1\n","CacheControl                  0.12.11\n","cachetools                    5.2.0\n","catalogue                     2.0.8\n","certifi                       2022.9.24\n","cffi                          1.15.1\n","cftime                        1.6.2\n","chardet                       3.0.4\n","charset-normalizer            2.1.1\n","click                         7.1.2\n","clikit                        0.6.2\n","cloudpickle                   1.5.0\n","cmake                         3.22.6\n","cmdstanpy                     1.0.8\n","colorcet                      3.0.1\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","confection                    0.0.3\n","cons                          0.4.5\n","contextlib2                   0.5.5\n","convertdate                   2.4.0\n","crashtest                     0.3.1\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cvxopt                        1.3.0\n","cvxpy                         1.2.2\n","cycler                        0.11.0\n","cymem                         2.0.7\n","Cython                        0.29.32\n","daft                          0.0.4\n","dask                          2022.2.1\n","datascience                   0.17.5\n","db-dtypes                     1.0.4\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.6\n","distributed                   2022.2.1\n","dlib                          19.24.0\n","dm-tree                       0.1.7\n","dnspython                     2.2.1\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.334\n","easydict                      1.10\n","ecos                          2.0.10\n","editdistance                  0.5.3\n","en-core-web-sm                3.4.1\n","entrypoints                   0.4\n","ephem                         4.1.3\n","et-xmlfile                    1.1.0\n","etils                         0.9.0\n","etuples                       0.3.8\n","fa2                           0.3.5\n","fastai                        2.7.10\n","fastcore                      1.5.27\n","fastdownload                  0.0.7\n","fastdtw                       0.3.4\n","fastjsonschema                2.16.2\n","fastprogress                  1.0.3\n","fastrlock                     0.8.1\n","feather-format                0.4.1\n","filelock                      3.8.0\n","firebase-admin                5.3.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   1.12\n","folium                        0.12.1.post1\n","frozenlist                    1.3.3\n","fsspec                        2022.11.0\n","future                        0.16.0\n","gast                          0.4.0\n","GDAL                          2.2.2\n","gdown                         4.4.0\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               2.8.2\n","google-api-python-client      1.12.11\n","google-auth                   2.15.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         3.3.6\n","google-cloud-bigquery-storage 2.16.2\n","google-cloud-core             2.3.2\n","google-cloud-datastore        2.9.0\n","google-cloud-firestore        2.7.2\n","google-cloud-language         2.6.1\n","google-cloud-storage          2.5.0\n","google-cloud-translate        3.8.4\n","google-colab                  1.0.0\n","google-crc32c                 1.5.0\n","google-pasta                  0.2.0\n","google-resumable-media        2.4.0\n","googleapis-common-protos      1.57.0\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      2.0.1\n","grpcio                        1.51.1\n","grpcio-status                 1.48.2\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.25.2\n","gym-notices                   0.0.8\n","h5py                          3.1.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.4\n","holidays                      0.17.2\n","holoviews                     1.14.9\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httpstan                      4.6.1\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","idna                          2.10\n","imageio                       2.9.0\n","imagesize                     1.4.1\n","imbalanced-learn              0.8.1\n","imblearn                      0.0\n","imgaug                        0.4.0\n","importlib-metadata            4.13.0\n","importlib-resources           5.10.0\n","imutils                       0.5.4\n","inflect                       2.1.0\n","intel-openmp                  2022.2.1\n","intervaltree                  2.1.0\n","ipykernel                     5.3.4\n","ipython                       7.9.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.7.1\n","itsdangerous                  1.1.0\n","jax                           0.3.25\n","jaxlib                        0.3.25+cuda11.cudnn805\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.2.0\n","jpeg4py                       0.1.4\n","jsonschema                    4.3.3\n","jupyter-client                6.1.12\n","jupyter-console               6.1.0\n","jupyter-core                  5.1.0\n","jupyterlab-widgets            3.0.3\n","kaggle                        1.5.12\n","kapre                         0.3.7\n","keras                         2.9.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.4\n","korean-lunar-calendar         0.3.1\n","langcodes                     3.3.0\n","libclang                      14.0.6\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.39.1\n","lmdb                          0.99\n","locket                        1.0.0\n","logical-unification           0.4.5\n","LunarCalendar                 0.0.9\n","lxml                          4.9.1\n","Markdown                      3.4.1\n","MarkupSafe                    2.0.1\n","marshmallow                   3.19.0\n","matplotlib                    3.2.2\n","matplotlib-venn               0.11.7\n","miniKanren                    1.0.3\n","missingno                     0.5.1\n","mistune                       0.8.4\n","mizani                        0.7.3\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                9.0.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.4\n","multidict                     6.0.3\n","multipledispatch              0.6.0\n","multitasking                  0.0.11\n","murmurhash                    1.0.9\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbconvert                     5.6.1\n","nbformat                      5.7.0\n","netCDF4                       1.6.2\n","networkx                      2.8.8\n","nibabel                       3.0.2\n","nltk                          3.7\n","notebook                      5.7.16\n","numba                         0.56.4\n","numexpr                       2.8.4\n","numpy                         1.21.6\n","oauth2client                  4.1.3\n","oauthlib                      3.2.2\n","okgrade                       0.4.3\n","opencv-contrib-python         4.6.0.66\n","opencv-python                 4.6.0.66\n","opencv-python-headless        4.6.0.66\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","osqp                          0.6.2.post0\n","packaging                     21.3\n","palettable                    3.3.0\n","pandas                        1.3.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.17.9\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.12.2\n","parso                         0.8.3\n","partd                         1.3.0\n","pastel                        0.2.1\n","pathlib                       1.0.1\n","pathy                         0.10.0\n","patsy                         0.5.3\n","pep517                        0.13.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","platformdirs                  2.5.4\n","plotly                        5.5.0\n","plotnine                      0.8.0\n","pluggy                        0.7.1\n","pooch                         1.6.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.3\n","preshed                       3.0.8\n","prettytable                   3.5.0\n","progressbar2                  3.38.0\n","prometheus-client             0.15.0\n","promise                       2.3\n","prompt-toolkit                2.0.10\n","prophet                       1.1.1\n","proto-plus                    1.22.1\n","protobuf                      3.19.6\n","psutil                        5.4.8\n","psycopg2                      2.9.5\n","ptyprocess                    0.7.0\n","py                            1.11.0\n","pyarrow                       9.0.0\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.6\n","pycparser                     2.21\n","pyct                          0.4.8\n","pydantic                      1.10.2\n","pydata-google-auth            1.4.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0.1\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pylev                         1.4.0\n","pymc                          4.1.4\n","PyMeeus                       0.5.11\n","pymongo                       4.3.3\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.9\n","pyrsistent                    0.19.2\n","pysimdjson                    3.2.0\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        3.3.0\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                7.0.0\n","python-utils                  3.4.5\n","pytz                          2022.6\n","pyviz-comms                   2.2.1\n","PyWavelets                    1.4.1\n","PyYAML                        6.0\n","pyzmq                         23.2.1\n","qdldl                         0.1.5.post2\n","qudida                        0.0.4\n","regex                         2022.6.2\n","requests                      2.23.0\n","requests-oauthlib             1.3.1\n","resampy                       0.4.2\n","rpy2                          3.5.5\n","rsa                           4.9\n","scikit-image                  0.18.3\n","scikit-learn                  1.0.2\n","scipy                         1.7.3\n","screen-resolution-extra       0.0.0\n","scs                           3.2.2\n","seaborn                       0.11.2\n","Send2Trash                    1.8.0\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.8.5.post1\n","six                           1.15.0\n","sklearn-pandas                1.8.0\n","smart-open                    5.2.1\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soundfile                     0.11.0\n","spacy                         3.4.3\n","spacy-legacy                  3.0.10\n","spacy-loggers                 1.0.3\n","Sphinx                        1.8.6\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.44\n","sqlparse                      0.4.3\n","srsly                         2.4.5\n","statsmodels                   0.12.2\n","sympy                         1.7.1\n","tables                        3.7.0\n","tabulate                      0.8.10\n","tblib                         1.7.0\n","tenacity                      8.1.0\n","tensorboard                   2.9.1\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.1\n","tensorflow                    2.9.2\n","tensorflow-datasets           4.6.0\n","tensorflow-estimator          2.9.0\n","tensorflow-gcs-config         2.9.1\n","tensorflow-hub                0.12.0\n","tensorflow-io-gcs-filesystem  0.28.0\n","tensorflow-metadata           1.11.0\n","tensorflow-probability        0.17.0\n","termcolor                     2.1.1\n","terminado                     0.13.3\n","testpath                      0.6.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","thinc                         8.1.5\n","threadpoolctl                 3.1.0\n","tifffile                      2022.10.10\n","toml                          0.10.2\n","tomli                         2.0.1\n","toolz                         0.12.0\n","torch                         1.13.0+cu116\n","torchaudio                    0.13.0+cu116\n","torchsummary                  1.5.1\n","torchtext                     0.14.0\n","torchvision                   0.14.0+cu116\n","tornado                       6.0.4\n","tqdm                          4.64.1\n","traitlets                     5.6.0\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typer                         0.7.0\n","typing-extensions             4.4.0\n","tzlocal                       1.5.1\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.10.1\n","wcwidth                       0.2.5\n","webargs                       8.2.0\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.38.4\n","widgetsnbextension            3.6.1\n","wordcloud                     1.8.2.2\n","wrapt                         1.14.1\n","xarray                        0.20.2\n","xarray-einstats               0.3.0\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.2.0\n","xlwt                          1.3.0\n","yarl                          1.8.2\n","yellowbrick                   1.5\n","zict                          2.2.0\n","zipp                          3.11.0\n"]}]},{"cell_type":"code","source":["!pip install -U textblob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spvX7a-Srgzj","executionInfo":{"status":"ok","timestamp":1670854358145,"user_tz":300,"elapsed":4453,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"6a591cd1-369a-446d-edd9-446cbf7a3e24"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (0.15.3)\n","Collecting textblob\n","  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 29.9 MB/s \n","\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n","Installing collected packages: textblob\n","  Attempting uninstall: textblob\n","    Found existing installation: textblob 0.15.3\n","    Uninstalling textblob-0.15.3:\n","      Successfully uninstalled textblob-0.15.3\n","Successfully installed textblob-0.17.1\n"]}]},{"cell_type":"code","source":["!pip show textblob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc14NnemrjMP","executionInfo":{"status":"ok","timestamp":1670854369758,"user_tz":300,"elapsed":5597,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"d0a186db-e416-4db8-cbeb-15d99cb79883"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: textblob\n","Version: 0.17.1\n","Summary: Simple, Pythonic text processing. Sentiment analysis, part-of-speech tagging, noun phrase parsing, and more.\n","Home-page: https://github.com/sloria/TextBlob\n","Author: Steven Loria\n","Author-email: sloria1@gmail.com\n","License: MIT\n","Location: /usr/local/lib/python3.8/dist-packages\n","Requires: nltk\n","Required-by: \n"]}]},{"cell_type":"code","source":["!pip install -U nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YppbWqPMr2q5","executionInfo":{"status":"ok","timestamp":1670854447047,"user_tz":300,"elapsed":3618,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"66a186ea-48d3-4e03-8e23-859f36932ad1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"]}]},{"cell_type":"code","source":["!pip show nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQAsQl5Ur40g","executionInfo":{"status":"ok","timestamp":1670854458270,"user_tz":300,"elapsed":6029,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"57e4d484-562b-4e10-c126-2e5f8b13df89"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: nltk\n","Version: 3.7\n","Summary: Natural Language Toolkit\n","Home-page: https://www.nltk.org/\n","Author: NLTK Team\n","Author-email: nltk.team@gmail.com\n","License: Apache License, Version 2.0\n","Location: /usr/local/lib/python3.8/dist-packages\n","Requires: joblib, click, tqdm, regex\n","Required-by: textblob\n"]}]},{"cell_type":"code","source":["import nltk "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ywg0-cgr9qW","executionInfo":{"status":"ok","timestamp":1670854475197,"user_tz":300,"elapsed":643,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"51a4600d-450a-4a18-c4c0-af268fde584a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"gdiJZcrxqe0M"},"outputs":[],"source":["# install the requirements\n","# pip install textblob"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"8TCUp2zdqe0R"},"source":["# `textblob`: otro módulo para tareas de PLN (`NLTK` + `pattern`)\n","\n","[textblob](http://textblob.readthedocs.org/) es una librería de procesamiento del texto para Python que permite realizar tareas de Procesamiento del Lenguaje Natural como análisis morfológico, extracción de entidades, análisis de opinión, traducción automática, etc. "]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"lUoErMc8qe0S"},"source":["Está construida sobre otras dos librerías muy famosas de Python: [NLTK](http://www.nltk.org/) y [pattern](http://www.clips.ua.ac.be/pages/pattern-en). La principal ventaja de [textblob](http://textblob.readthedocs.org/) es que permite combinar el uso de las dos herramientas anteriores en un interfaz más simple.\n","\n","Vamos a apoyarnos en [este tutorial](http://textblob.readthedocs.org/en/dev/quickstart.html) para aprender a utilizar algunas de sus funcionalidades más llamativas. \n","\n","Lo primero es importar el objeto `TextBlob` que nos permite acceder a todas las herramentas que incluye."]},{"cell_type":"code","execution_count":4,"metadata":{"Collapsed":"false","id":"dW4Xo_KRqe0T","executionInfo":{"status":"ok","timestamp":1670854413125,"user_tz":300,"elapsed":1688,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}}},"outputs":[],"source":["from textblob import TextBlob"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"W7SNnmy3qe0T"},"source":["Vamos a crear nuestro primer ejemplo de *textblob* a través del objeto `TextBlob`. Piensa en estos *textblobs* como una especie de cadenas de texto de Python, analaizadas y enriquecidas con algunas características extra. "]},{"cell_type":"code","execution_count":57,"metadata":{"Collapsed":"false","id":"gRZqMuKtqe0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855659200,"user_tz":300,"elapsed":1005,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"c2dd78f3-1a2a-4551-d34b-21b36ee4f307"},"outputs":[{"output_type":"stream","name":"stdout","text":["In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy. The consumers who \n","participate deserve a very clear picture of the risks they're taking\n"]}],"source":["texto = \"\"\"In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy. The consumers who \n","participate deserve a very clear picture of the risks they're taking\"\"\"\n","\n","print(texto) \n","\n","t = TextBlob(texto)"]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyFkE-06spkE","executionInfo":{"status":"ok","timestamp":1670855661457,"user_tz":300,"elapsed":118,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"abee1a8f-c46f-49d3-92e9-73bf655074dd"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","execution_count":59,"metadata":{"Collapsed":"false","id":"vTWkvBg_qe0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855663730,"user_tz":300,"elapsed":195,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"cf875e51-f18e-4404-a0f6-8214d09b1cbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Sentence(\"In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy.\"), Sentence(\"The consumers who \n","participate deserve a very clear picture of the risks they're taking\")]\n"]}],"source":["# Parse into sentences\n","\n","print(t.sentences)"]},{"cell_type":"code","execution_count":60,"metadata":{"Collapsed":"false","id":"nw-66f0rqe0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855666193,"user_tz":300,"elapsed":3,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"e7b4ce1e-eb6d-4520-febe-0f602a2337a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tenemos 2 oraciones.\n","\n","In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy.\n","---------------------------------------------------------------------------\n","The consumers who \n","participate deserve a very clear picture of the risks they're taking\n","---------------------------------------------------------------------------\n"]}],"source":["print(\"Tenemos\", len(t.sentences), \"oraciones.\\n\")\n","\n","for sentence in t.sentences:\n","    print(sentence)\n","    print(\"-\" * 75)"]},{"cell_type":"code","source":["print(\"Tenemos\", len(t.sentences), \"oraciones.\\n\")\n","\n","oracion_ls = []\n","\n","for sentence in t.sentences:\n","    print(sentence)\n","    sentence_str = str(sentence)\n","    print(type(sentence_str))\n","    print(sentence_str)\n","    oracion_ls.append(sentence_str)\n","    print(\"-\" * 75)\n","\n","print(f'\\n\\nORACION:\\n\\n{oracion_ls}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gC1RTE3PwxFo","executionInfo":{"status":"ok","timestamp":1670855831610,"user_tz":300,"elapsed":3,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"f04bdc65-e931-487c-8230-3f760ce56a89"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Tenemos 2 oraciones.\n","\n","In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy.\n","<class 'str'>\n","In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy.\n","---------------------------------------------------------------------------\n","The consumers who \n","participate deserve a very clear picture of the risks they're taking\n","<class 'str'>\n","The consumers who \n","participate deserve a very clear picture of the risks they're taking\n","---------------------------------------------------------------------------\n","\n","\n","ORACION:\n","\n","['In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \\nand San Francisco counties make an important point about the lightly regulated sharing economy.', \"The consumers who \\nparticipate deserve a very clear picture of the risks they're taking\"]\n"]}]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"b8MgITrUqe0V"},"source":["## Procesando oraciones, palabras y entidades\n","\n","Podemos segmentar en oraciones y en palabras nuestra texto de ejemplo simplemente accediendo a las propiedades `.sentences` y `.words`. Imprimimos por pantalla: "]},{"cell_type":"code","source":["# imprimimos las oraciones\n","for sentence in t.sentences:\n","    print(sentence)\n","    print(\"-\" * 75)\n","\n","# y las palabras\n","print(t.words)\n","print(texto.split())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQVrEerpwu42","executionInfo":{"status":"ok","timestamp":1670855860012,"user_tz":300,"elapsed":215,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"e078373a-0edb-4a00-f9a1-e75f226620f6"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy.\n","---------------------------------------------------------------------------\n","The consumers who \n","participate deserve a very clear picture of the risks they're taking\n","---------------------------------------------------------------------------\n","['In', 'new', 'lawsuits', 'brought', 'against', 'the', 'ride-sharing', 'companies', 'Uber', 'and', 'Lyft', 'the', 'top', 'prosecutors', 'in', 'Los', 'Angeles', 'and', 'San', 'Francisco', 'counties', 'make', 'an', 'important', 'point', 'about', 'the', 'lightly', 'regulated', 'sharing', 'economy', 'The', 'consumers', 'who', 'participate', 'deserve', 'a', 'very', 'clear', 'picture', 'of', 'the', 'risks', 'they', \"'re\", 'taking']\n","['In', 'new', 'lawsuits', 'brought', 'against', 'the', 'ride-sharing', 'companies', 'Uber', 'and', 'Lyft,', 'the', 'top', 'prosecutors', 'in', 'Los', 'Angeles', 'and', 'San', 'Francisco', 'counties', 'make', 'an', 'important', 'point', 'about', 'the', 'lightly', 'regulated', 'sharing', 'economy.', 'The', 'consumers', 'who', 'participate', 'deserve', 'a', 'very', 'clear', 'picture', 'of', 'the', 'risks', \"they're\", 'taking']\n"]}]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"1NdQk1hrqe0W"},"source":["La propiedad `.noun_phrases` nos permite acceder a la lista de entidades (en realidad, son sintagmas nominales) incluídos en nuestro *textblob*. Así es como funciona."]},{"cell_type":"code","source":["nltk.download('brown')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gmhC_O_skem","executionInfo":{"status":"ok","timestamp":1670855863289,"user_tz":300,"elapsed":2,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"3d8aa284-cdc0-4e52-b7b4-4f7399777447"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","execution_count":67,"metadata":{"Collapsed":"false","id":"e9ujrv1Tqe0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855865600,"user_tz":300,"elapsed":3,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"df1eae05-9904-440a-b216-70133f954a8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["el texto de ejemplo contiene 8 entidades\n","- new lawsuits\n","- uber\n","- lyft\n","- top prosecutors\n","- los angeles\n","- san francisco\n","- important point\n","- clear picture\n"]}],"source":["print(\"el texto de ejemplo contiene\", len(t.noun_phrases), \"entidades\")\n","for element in t.noun_phrases:\n","    print(\"-\", element)"]},{"cell_type":"code","source":["nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gq3yYYrssgn1","executionInfo":{"status":"ok","timestamp":1670854669936,"user_tz":300,"elapsed":230,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"8b559643-7057-4346-a793-1da768e34ae1"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","execution_count":22,"metadata":{"Collapsed":"false","id":"YAL63LW8qe0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670854674254,"user_tz":300,"elapsed":2031,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"3514d96d-2edf-4f4d-d08c-947135f55871"},"outputs":[{"output_type":"stream","name":"stdout","text":["In In Ins\n","new new news\n","lawsuit lawsuits lawsuit\n","brought brought broughts\n","against against againsts\n","the the thes\n","ride-sharing ride-sharing ride-sharings\n","company companies company\n","Uber Uber Ubers\n","and and ands\n","Lyft Lyft Lyfts\n","the the thes\n","top top tops\n","prosecutor prosecutors prosecutor\n","in in ins\n","Los Los Lo\n","Angeles Angeles Angele\n","and and ands\n","San San Sans\n","Francisco Francisco Franciscoes\n","county counties county\n","make make makes\n","an an some\n","important important importants\n","point point points\n","about about abouts\n","the the thes\n","lightly lightly lightlies\n","regulated regulated regulateds\n","sharing sharing sharings\n","economy economy economies\n","The The Thes\n","consumer consumers consumer\n","who who whoes\n","participate participate participates\n","deserve deserve deserves\n","a a some\n","very very veries\n","clear clear clears\n","picture picture pictures\n","of of ofs\n","the the thes\n","risk risks risk\n","they they they\n","'re 're 'res\n","taking taking takings\n"]}],"source":["# jugando con lemas, singulares y plurales\n","for word in t.words:\n","    if word.endswith(\"s\"):\n","        print(word.lemmatize(), word, word.singularize())\n","    else:\n","        print(word.lemmatize(), word, word.pluralize())"]},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2xXCjMIs6td","executionInfo":{"status":"ok","timestamp":1670854734089,"user_tz":300,"elapsed":212,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"6248ade5-a64f-4a4d-b485-e7c1adc66d4f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":26,"metadata":{"Collapsed":"false","id":"LNI8vMEgqe0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670854735945,"user_tz":300,"elapsed":277,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"8f3e5d2d-5943-4989-d1da-8be6c8253cf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["In In\n","new new\n","lawsuits --> lawsuit\n","brought brought\n","against against\n","the the\n","ride-sharing ride-sharing\n","companies --> company\n","Uber Uber\n","and and\n","Lyft Lyft\n","the the\n","top top\n","prosecutors --> prosecutor\n","in in\n","Los Los\n","Angeles Angeles\n","and and\n","San San\n","Francisco Francisco\n","counties --> county\n","make make\n","an an\n","important important\n","point --> points\n","about about\n","the the\n","lightly lightly\n","regulated regulated\n","sharing sharing\n","economy --> economies\n","The The\n","consumers --> consumer\n","who who\n","participate participate\n","deserve deserve\n","a a\n","very very\n","clear clear\n","picture --> pictures\n","of of\n","the the\n","risks --> risk\n","they they\n","'re 're\n","taking taking\n"]}],"source":["# ¿cómo podemos hacer la lematización más inteligente?\n","for item in t.tags:\n","    if item[1] == \"NN\":\n","        print(item[0], \"-->\", item[0].pluralize())\n","    elif item[1] == \"NNS\":\n","        print(item[0], \"-->\", item[0].singularize())\n","    else:\n","        print(item[0], item[0].lemmatize())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"XnsvJHh1qe0Z"},"source":["## Análisis sintático\n","\n","Aunque podemos utilizar otros analizadores, por defecto el método `.parse()` invoca al analizador morfosintáctico del módulo  `pattern.en` que ya conoces."]},{"cell_type":"code","execution_count":27,"metadata":{"Collapsed":"false","id":"XGHGy4s4qe0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670854742278,"user_tz":300,"elapsed":707,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"736b0acd-4238-4a47-848f-ac44dfe560f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["In/IN/B-PP/B-PNP new/JJ/B-NP/I-PNP lawsuits/NNS/I-NP/I-PNP brought/VBN/B-VP/I-PNP against/IN/B-PP/B-PNP the/DT/B-NP/I-PNP ride-sharing/JJ/I-NP/I-PNP companies/NNS/I-NP/I-PNP Uber/NNP/I-NP/I-PNP and/CC/O/O Lyft/NNP/B-NP/O ,/,/O/O the/DT/B-NP/O top/JJ/I-NP/O prosecutors/NNS/I-NP/O in/IN/B-PP/B-PNP Los/NNP/B-NP/I-PNP Angeles/NNP/I-NP/I-PNP and/CC/I-NP/I-PNP San/NNP/I-NP/I-PNP Francisco/NNP/I-NP/I-PNP counties/NNS/I-NP/I-PNP make/VB/B-VP/O an/DT/B-NP/O important/JJ/I-NP/O point/NN/I-NP/O about/IN/B-PP/O the/DT/O/O lightly/RB/B-VP/O regulated/VBN/I-VP/O sharing/VBG/I-VP/O economy/NN/B-NP/O ././O/O\n","The/DT/B-NP/O consumers/NNS/I-NP/O who/WP/O/O participate/VB/B-VP/O deserve/VBP/I-VP/O a/DT/B-NP/O very/RB/I-NP/O clear/JJ/I-NP/O picture/NN/I-NP/O of/IN/B-PP/B-PNP the/DT/B-NP/I-PNP risks/NNS/I-NP/I-PNP they/PRP/I-NP/I-PNP '/POS/O/O re/NN/B-NP/O taking/VBG/B-VP/O\n"]}],"source":["# análisis sintáctico\n","print(t.parse())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"pMIKlaI7qe0Z"},"source":["## Traducción automática\n","\n","\n","A partir de cualquier texto procesado con `TextBlob`, podemos acceder a un traductor automático de bastante calidad con el método `.translate`. Fíjate en cómo lo usamos. Es obligatorio indicar la lengua de destinto. La lengua de origen, se puede predecir a partir del texto de entrada. "]},{"cell_type":"code","execution_count":37,"metadata":{"Collapsed":"false","id":"nJNcuJVoqe0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855115536,"user_tz":300,"elapsed":5433,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"3cda6c5f-e1f3-4292-ed1d-443bf9001377"},"outputs":[{"output_type":"stream","name":"stdout","text":["China Lunar Exploration Project is also known as Chang'e Project. It is the first lunar exploration project launched by China. It was officially launched on March 1, 2003\n","El Proyecto de Exploración Lunar de China también se conoce como Proyecto Chang'e. Es el primer proyecto de exploración lunar lanzado por China. Se lanzó oficialmente el 1 de marzo de 2003\n","In 1943 she was sent to the United States, where she spoke in defense of the British White Book, after which she worked in Canada and India.\n","En 1943 fue enviada a los Estados Unidos, donde habló en defensa del libro blanco británico, después de lo cual trabajó en Canadá e India.\n","--------------\n","Το δημόσιο χρέος σημείωσε νέα αρχεία στην Ισπανία το τρίτο τρίμηνο\n","Государственный долг отметил новые записи в Испании в третьем квартале\n","Zor publikoak erregistro berriak markatu ditu Espainian hirugarren hiruhilekoan\n","Julkinen velka on merkinnyt uusia tietueita Espanjassa kolmannella vuosineljänneksellä\n","La dette publique a marqué de nouveaux records en Espagne au troisième trimestre\n","De overheidsschuld heeft in het derde kwartaal nieuwe records gemarkeerd in Spanje\n","A débeda pública marcou novos rexistros en España no terceiro trimestre\n","El deute públic ha marcat nous registres a Espanya al tercer trimestre\n","公共债务在第三季度标志着西班牙的新记录\n","Public Debitum notatum novum records in Hispania in tertia quartam\n","Ve třetím čtvrtletí ve Španělsku znamenal veřejný dluh ve Španělsku ve Španělsku\n","--------------\n","Sono Andato A Milano and my sono funny a Bordello.\n","La deuda pública ha marcado nuevos récords en España en el tercer trimestre\n"]}],"source":["# de chino a inglés y español\n","oracion_zh = \"中国探月工程 亦稱嫦娥工程，是中国启动的第一个探月工程，于2003年3月1日正式启动\"\n","t_zh = TextBlob(oracion_zh)\n","print(t_zh.translate(from_lang=\"zh-CN\", to=\"en\"))\n","print(t_zh.translate(from_lang=\"zh-CN\", to=\"es\"))\n","\n","oracion_ru = \"В 1943 году была отправлена в США, где выступала в защиту британской «белой книги», после чего работала в Канаде и Индии.\"\n","t_ru = TextBlob(oracion_ru)\n","print(t_ru.translate(from_lang=\"ru\", to=\"en\"))\n","print(t_ru.translate(from_lang=\"ru\", to=\"es\"))\n","\n","print(\"--------------\")\n","\n","t_es = TextBlob(\n","    \"La deuda pública ha marcado nuevos récords en España en el tercer trimestre\"\n",")\n","\n","# ERROR:  ---> 17 print(t_es.translate(to=\"el\"))\n","#         AttributeError: 'list' object has no attribute 'strip'\n","#         textblob-0.17.1\n","#         fix: add [from_lang=\"es\",] in calls to t_es.translate() \n","#         20221212\n","\n","print(t_es.translate(from_lang=\"es\", to=\"el\"))\n","print(t_es.translate(from_lang=\"es\", to=\"ru\"))\n","print(t_es.translate(from_lang=\"es\", to=\"eu\"))\n","print(t_es.translate(from_lang=\"es\", to=\"fi\"))\n","print(t_es.translate(from_lang=\"es\", to=\"fr\"))\n","print(t_es.translate(from_lang=\"es\", to=\"nl\"))\n","print(t_es.translate(from_lang=\"es\", to=\"gl\"))\n","print(t_es.translate(from_lang=\"es\", to=\"ca\"))\n","print(t_es.translate(from_lang=\"es\", to=\"zh\"))\n","print(t_es.translate(from_lang=\"es\", to=\"la\"))\n","print(t_es.translate(from_lang=\"es\", to=\"cs\"))\n","\n","# con el slang no funciona tan bien\n","print(\"--------------\")\n","t_ita = TextBlob(\"Sono andato a Milano e mi sono divertito un bordello.\")\n","print(t_ita.translate(from_lang=\"es\", to=\"en\"))\n","# print(t_ita.translate(to=\"es\"))\n","print(t_es)"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"K3wAGR5Wqe0a"},"source":["## WordNet\n","\n","`textblob`, más concretamente, cualquier objeto de la clase `Word`, nos permite acceder a la información de WordNet. "]},{"cell_type":"code","execution_count":38,"metadata":{"Collapsed":"false","id":"ih5dgE2Tqe0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855128679,"user_tz":300,"elapsed":220,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"226f5ce4-fd0f-4776-d05a-4d056aac8f68"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n","[Synset('chop.v.05'), Synset('hack.v.02'), Synset('hack.v.03'), Synset('hack.v.04'), Synset('hack.v.05'), Synset('hack.v.06'), Synset('hack.v.07'), Synset('hack.v.08')]\n","['a motor vehicle with four wheels; usually propelled by an internal combustion engine', 'a wheeled vehicle adapted to the rails of railroad', 'the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant', 'where passengers ride up and down', 'a conveyance for passengers or freight on a cable railway']\n","[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')]]\n","[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('car.n.02')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('car.n.02')]]\n","[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('car.n.03')]]\n","[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('car.n.04')]]\n","[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('cable_car.n.01')]]\n"]}],"source":["# WordNet\n","from textblob import Word\n","from textblob.wordnet import VERB\n","\n","# ¿cuántos synsets tiene \"car\"\n","word = Word(\"car\")\n","print(word.synsets)\n","\n","# dame los synsets de la palabra \"hack\" como verbo\n","print(Word(\"hack\").get_synsets(pos=VERB))\n","\n","# imprime la lista de definiciones de \"car\"\n","print(Word(\"car\").definitions)\n","\n","# recorre la jerarquía de hiperónimos\n","for s in word.synsets:\n","    print(s.hypernym_paths())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"TMK8PUieqe0a"},"source":["## Análisis de opinion"]},{"cell_type":"code","execution_count":39,"metadata":{"Collapsed":"false","id":"CWKUF6lnqe0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855135144,"user_tz":300,"elapsed":1173,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"549e55bb-84a3-4d39-89c1-1e2d4338a7c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment(polarity=0.5387784090909091, subjectivity=0.6011363636363636)\n","Sentiment(polarity=0.0, subjectivity=0.0)\n","0.5387784090909091\n","Hey, esto es una opinion\n"]}],"source":["# análisis de opinión\n","opinion1 = TextBlob(\"This new restaurant is great. I had so much fun!! :-P\")\n","print(opinion1.sentiment)\n","\n","opinion2 = TextBlob(\"Google News to close in Spain.\")\n","print(opinion2.sentiment)\n","\n","# subjetividad 0:1\n","# polaridad -1:1\n","\n","print(opinion1.sentiment.polarity)\n","\n","if opinion1.sentiment.subjectivity > 0.5:\n","    print(\"Hey, esto es una opinion\")"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"C3eBXNygqe0b"},"source":["### Ejercicio 1\n","\n","Prueba a analizar distintas oraciones en inglés (combinando verbos que indican información subjetiva, palabras con distinta carga emocional, añadiendo emoticonos, etc.) para ver si eres capaz de entender el funcionamiento de este analizador de opiniones."]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"rY8jjV5wqe0b"},"outputs":[],"source":["# escribe tu código aquí"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"zf89bEOHqe0b"},"source":["`TextBlob` da acceso a [otro tipo de analizadores](https://textblob.readthedocs.io/en/dev/advanced_usage.html#sentiment-analyzers) de opinión, por ejemplo, un clasificador basado en *Naive Bayes*. Prueba qué tal funciona:"]},{"cell_type":"code","source":["%whos"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3akUd6ofuvzA","executionInfo":{"status":"ok","timestamp":1670855201257,"user_tz":300,"elapsed":138,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"856d9201-ba1b-4a95-9ec3-b2fea1e95fb3"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Variable             Type        Data/Info\n","------------------------------------------\n","NaiveBayesAnalyzer   ABCMeta     <class 'textblob.en.senti<...>ents.NaiveBayesAnalyzer'>\n","TextBlob             type        <class 'textblob.blob.TextBlob'>\n","VERB                 str         v\n","Word                 type        <class 'textblob.blob.Word'>\n","b1                   TextBlob    I havv goood speling!\n","b2                   TextBlob    Miy naem iz Jonh!\n","b3                   TextBlob    Boyz dont cri\n","b4                   TextBlob    psicological posesion achifmen comitment\n","element              Word        clear picture\n","item                 tuple       n=2\n","nltk                 module      <module 'nltk' from '/usr<...>ckages/nltk/__init__.py'>\n","opinion1             TextBlob    This new restaurant is gr<...>. I had so much fun!! :-P\n","opinion2             TextBlob    Google News to close in Spain.\n","oracion_ru           str         В 1943 году была отправле<...>аботала в Канаде и Индии.\n","oracion_zh           str         中国探月工程 亦稱嫦娥工程，是中国启动的第一个探月工程，于2003年3月1日正式启动\n","s                    Synset      Synset('cable_car.n.01')\n","sentence             Sentence    The consumers who \\nparti<...> the risks they're taking\n","t                    TextBlob    In new lawsuits brought a<...> the risks they're taking\n","t_es                 TextBlob    La deuda pública ha marca<...>ña en el tercer trimestre\n","t_ita                TextBlob    Sono andato a Milano e mi<...>no divertito un bordello.\n","t_ru                 TextBlob    В 1943 году была отправле<...>аботала в Канаде и Индии.\n","t_zh                 TextBlob    中国探月工程 亦稱嫦娥工程，是中国启动的第一个探月工程，于2003年3月1日正式启动\n","texto                str         In new lawsuits brought a<...> the risks they're taking\n","word                 Word        car\n"]}]},{"cell_type":"code","source":["oracion = []\n","\n","for sentence in t.sentences:\n","    oracion.append(str(sentence))\n","    print(f'Added: {str(sentence)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWnugqltvAjU","executionInfo":{"status":"ok","timestamp":1670855433945,"user_tz":300,"elapsed":2,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"0c00d2c0-d629-47ef-81f4-0b82746baad0"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Added: i\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"F0ruxHu-vkNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('movie_reviews')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NYjF-U-vWn-","executionInfo":{"status":"ok","timestamp":1670855358354,"user_tz":300,"elapsed":1383,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"256e2218-4b0c-4dad-b270-c76c0c2907e4"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","execution_count":50,"metadata":{"Collapsed":"false","id":"1tRYoV_kqe0b","colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"status":"error","timestamp":1670855407251,"user_tz":300,"elapsed":47421,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"eb5ca15e-3d62-4683-c17f-63de10a57907"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n","Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-598bb868b14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moracion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moracion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnamedtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/base.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Analyze text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mneg_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mpos_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         neg_feats = [(self.feature_extractor(\n\u001b[0m\u001b[1;32m     77\u001b[0m             nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n\u001b[1;32m     78\u001b[0m         pos_feats = [(self.feature_extractor(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mneg_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mpos_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         neg_feats = [(self.feature_extractor(\n\u001b[0m\u001b[1;32m     77\u001b[0m             nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n\u001b[1;32m     78\u001b[0m         pos_feats = [(self.feature_extractor(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m_default_feature_extractor\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Default feature extractor for the NaiveBayesAnalyzer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Default feature extractor for the NaiveBayesAnalyzer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Open the stream, if it's not open already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# If the file is empty, the while loop will never run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from textblob.sentiments import NaiveBayesAnalyzer\n","\n","# for oracion in oraciones:\n","for oracion in oracion:\n","    t = TextBlob(oracion, analyzer=NaiveBayesAnalyzer())\n","    print(t.sentiment)"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"4GiTX73oqe0b"},"source":["## Otras curiosidades"]},{"cell_type":"code","execution_count":41,"metadata":{"Collapsed":"false","id":"_oAvJr8Oqe0b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670855174512,"user_tz":300,"elapsed":2322,"user":{"displayName":"Jon Chun","userId":"14430240466678867548"}},"outputId":"2bf5efa8-0de3-4d89-d13c-0cf967fd6555"},"outputs":[{"output_type":"stream","name":"stdout","text":["I have good spelling!\n","In name in On!\n","Boy dont cry\n","psychological position achifmen commitment\n"]}],"source":["#  corrección ortográfica\n","b1 = TextBlob(\"I havv goood speling!\")\n","print(b1.correct())\n","\n","b2 = TextBlob(\"Miy naem iz Jonh!\")\n","print(b2.correct())\n","\n","b3 = TextBlob(\"Boyz dont cri\")\n","print(b3.correct())\n","\n","b4 = TextBlob(\"psicological posesion achifmen comitment\")\n","print(b4.correct())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"HGIkvPwTqe0b"},"source":["## Hasta el infinito, y más allá\n","\n","En este breve resumen solo consideramos las posibilidades que ofrece `TextBlob` por defecto. Pero si necesitas personalizar las herramientas, echa un vistazo a [la documentación avanzada](http://textblob.readthedocs.org/en/dev/advanced_usage.html#advanced). "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[{"file_id":"https://github.com/vitojph/kschool-nlp-18/blob/master/notebooks/textblob.ipynb","timestamp":1670854171605}],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}